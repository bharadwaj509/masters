{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- check counts\n",
      "424953 3673\n",
      "517717 4400\n",
      "445874 3744\n",
      "----- postive and -ve sentences\n",
      "4464 1384080\n",
      "5301 1383243\n",
      "5356 1383188\n",
      "1388544\n",
      "----- postive and -ve sentence count\n",
      "1388544 0\n",
      "1388544 0\n",
      "1388544 0\n",
      "1388544\n",
      "---\n",
      "3673\n",
      "4400\n",
      "3744\n",
      "0\n",
      "--\n",
      "11817\n",
      "3673\n",
      "4400\n",
      "3744\n",
      "0\n",
      "1388544\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Train'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "# Sentence Lists\n",
    "sentence_text = []\n",
    "sentence_class = []\n",
    "\n",
    "\n",
    "\n",
    "#action first party\n",
    "total_data_samples0 = []\n",
    "total_data_number0 = []\n",
    "total_data_label0 = []\n",
    "\n",
    "#Personal Info Type\n",
    "total_data_samples1 = []\n",
    "total_data_number1 = []\n",
    "total_data_label1 = []\n",
    "\n",
    "\n",
    "#Purpose\n",
    "total_data_samples2 = []\n",
    "total_data_number2 = []\n",
    "total_data_label2 = []\n",
    "\n",
    "\n",
    "#None\n",
    "total_data_samples3 = []\n",
    "total_data_number3 = []\n",
    "total_data_label3 = []\n",
    "\n",
    "#checking counts, we can remove them later\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "#checking counts, we can remove them later\n",
    "count_11 = 0\n",
    "count_22 = 0\n",
    "count_33 = 0\n",
    "\n",
    "cnt = 0\n",
    "cnt0 = 0\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "cnt3 = 0\n",
    "choice = 0\n",
    "allFiles = allFiles[:85]\n",
    "\n",
    "\n",
    "# all the followint positives are to be counted if the sentences are in that particular class. \n",
    "# A sen_neg to be counted in any other circumstances\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_actioFP = []\n",
    "sen_actioFP_class = []\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_personalIT = []\n",
    "sen_personalIT_class = []\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "sen_purpose = []\n",
    "sen_purpose_class = []\n",
    "\n",
    "sen3_pos = 0\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "#     print(len(list(soup.descendants)))\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "#         print(element)\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "#                 print(len(string))\n",
    "                start_index.append(count)\n",
    "#                 print(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "sentence_list = []\n",
    "\n",
    "for file in allFiles:\n",
    "    dictCollection = {\"Action First-Party\":[],\n",
    "                      \"Purpose\":[],\n",
    "                      \"Personal Information Type\":[],\n",
    "                      \"None\":[]\n",
    "                      }\n",
    "\n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    # df_tail = df.tail(1)[4]\n",
    "    # print(df_tail)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Train/', 1)[1]\n",
    "#     print(file)\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = 'Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "#     print(file_html)\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "#     print(len(indeces))\n",
    "#     print(len(ls))\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "#             choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "            if parse_json[\"Action First-Party\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1\n",
    "                count_11 += 1\n",
    "                total_data_samples0.append(parse_json[\"Action First-Party\"][\"selectedText\"])\n",
    "                total_data_number0.append(0)\n",
    "                total_data_label0.append(\"Action First-Party\")\n",
    "                str_index = parse_json[\"Action First-Party\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Action First-Party\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_1 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Action_First-Party_positive\",\"positive\"])\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Action_First-Party_positive\")\n",
    "                        sen0_pos += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"pos\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")\n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Action_First-Party_negative\",\"negative\"])\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Action_First-Party_negative\")\n",
    "                cnt0 = cnt0+1\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1\n",
    "                count_22 += 1\n",
    "                total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                total_data_number1.append(1)\n",
    "                total_data_label1.append(\"Personal Information Type\")                \n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_2 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "                        sen1_pos += 1\n",
    "                        sen0_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"pos\")                        \n",
    "                        sen_purpose_class.append(\"neg\")                       \n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "                        sen1_neg += 1\n",
    "                        sen0_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")                        \n",
    "                cnt1 = cnt1+1\n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1            \n",
    "                count_33 += 1                \n",
    "                total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "                total_data_number2.append(2)\n",
    "                total_data_label2.append(\"Purpose\")     \n",
    "                str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_3 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Purpose_positive\")\n",
    "                        sen2_pos += 1\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"pos\")                        \n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "                        sentence_text.append(ls[index])\n",
    "                        sentence_class.append(\"Purpose_negative\")\n",
    "                        sen2_neg += 1\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")                        \n",
    "                cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "# #             print(parse_json)\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "#                 total_data_number1.append(1)\n",
    "#                 total_data_label1.append(\"Personal Information Type\")\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "#                 total_data_number2.append(2)\n",
    "#                 total_data_label2.append(\"Purpose\") \n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_3 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Purpose_positive\")\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Purpose_negative\")\n",
    "#                         sen2_neg += 1\n",
    "#                 cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"User Choice/Control\":\n",
    "# #             choice = 1\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "# #                 print(parse_json[\"Personal Information Type\"][\"startIndexInSegment\"],parse_json[\"Personal Information Type\"][\"endIndexInSegment\"])\n",
    "#                 total_data_number1.append(1)\n",
    "#                 total_data_label1.append(\"Personal Information Type\")\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "#                 total_data_number2.append(2)\n",
    "#                 total_data_label2.append(\"Purpose\")\n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_3 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Purpose_positive\")\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Purpose_negative\")\n",
    "#                         sen2_neg += 1\n",
    "#                 cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"Data Retention\":\n",
    "# #             choice = 1\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "#                 total_data_number1.append(1)\n",
    "#                 total_data_label1.append(\"Personal Information Type\")\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         sentence_text.append(ls[index])\n",
    "#                         sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#         if choice==0:\n",
    "# #             print(\"practis is -->\", df[5][i])\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "# #             print(parse_json)\n",
    "# #             print(len(df[6][i]))\n",
    "# #             print(parse_json.keys())\n",
    "#             attributes = parse_json.keys()\n",
    "# #             print(attributes)\n",
    "#             for k in attributes:\n",
    "# #                 print(k)\n",
    "#                 if parse_json[k]['startIndexInSegment'] != -1:\n",
    "# #                     print(parse_json[k]['selectedText'])\n",
    "#                     total_data_samples3.append(parse_json[k]['selectedText'])\n",
    "#                     total_data_number3.append(3)\n",
    "#                     total_data_label3.append(\"None\")\n",
    "#                     str_index = parse_json[k][\"startIndexInSegment\"]\n",
    "#                     end_index = parse_json[k][\"endIndexInSegment\"]\n",
    "#                     for index in range(len(ls)):\n",
    "#                         count_3 += 1\n",
    "#                         if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                            (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                            (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                            (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                             sentence_list.append([ls[index],\"None_positive\",\"positive\"])\n",
    "#                             sentence_text.append(ls[index])\n",
    "#                             sentence_class.append(\"none\")\n",
    "#                             sen3_pos += 1\n",
    "                        \n",
    "#                     cnt3 = cnt3+1\n",
    "\n",
    "                \n",
    "# print(\"----- check counts\")                \n",
    "# print(count_1, count_11)\n",
    "# print(count_2, count_22)\n",
    "# print(count_3, count_33)                \n",
    "                                \n",
    "print(\"----- postive and -ve sentences\")                \n",
    "print(sen0_pos,sen0_neg)\n",
    "print(sen1_pos,sen1_neg)\n",
    "print(sen2_pos,sen2_neg)\n",
    "print(len(sentence_list))\n",
    "\n",
    "print(\"----- postive and -ve sentence count\")\n",
    "print(len(sen_actioFP),len(sen_actioFP_neg))\n",
    "print(len(sen_personalIT),len(sen_personalIT_neg))\n",
    "print(len(sen_purpose),len(sen_purpose_neg))\n",
    "print(len(sentence_list))\n",
    "\n",
    "\n",
    "# print(\"---\")\n",
    "# print(cnt0)\n",
    "# print(cnt1)\n",
    "# print(cnt2)\n",
    "# print(cnt3)\n",
    "# print(\"--\")\n",
    "# print(cnt0+cnt1+cnt2+cnt3)\n",
    "# print(len(total_data_samples0))\n",
    "# print(len(total_data_samples1))\n",
    "# print(len(total_data_samples2))\n",
    "# print(len(total_data_samples3)) # 22536 8780\n",
    "\n",
    "# print(len(sentence_text))\n",
    "\n",
    "#942670\n",
    "#942670"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Privacy Policy\\nSci-News.com is committed to protecting and respecting your privacy.', 'To better inform you of our policy concerning user privacy, we have adopted the following terms.', 'Please note that these terms are subject to change, and any such changes will be included on this page.', '|||Information that Sci-News.com May Collect Online\\nSci-News.com may collect and process the following data about you:\\n- information that you provide by filling in forms on our site, including names, e-mail and website addresses; we may also ask you for information for other purposes, for example when you report a problem with our site;\\n|||- if you contact us, we may keep a record of that correspondence;\\n|||- details of your visits to our site including, but not limited to, traffic data, location data, weblogs and other communication data.', '|||Sci-News.com does not knowingly collect or solicit personal information from anyone under the age of 13.', 'We assume that minors 13 years of age or older have received permission from their parents or guardians before using this website.', 'Parents or guardians may contact us at privacy@sci-news.com with questions or concerns about our privacy policy.', '|||Use of Cookies\\nSci-News.com uses cookie technology.', 'A cookie is a small amount of data, which often includes a unique identifier that is sent to your computer or mobile phone browser from a websites computer and is stored on your devices hard drive.', 'A website can send its own cookie to your browser if your browsers preferences allow it, but your browser only permits a website to access the cookies it has already sent to you, not the cookies sent to you by other websites.']\n"
     ]
    }
   ],
   "source": [
    "print(sen_actioFP[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of all files 25\n",
      "----- postive and -ve sentences\n",
      "1791 673428\n",
      "2286 672933\n",
      "2175 673044\n",
      "675219\n",
      "----- postive and -ve sentences count\n",
      "675219 675219\n",
      "675219 675219\n",
      "675219 675219\n",
      "675219\n"
     ]
    }
   ],
   "source": [
    "### Extraacing the test data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Test'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "print(\"len of all files\", len(allFiles))\n",
    "\n",
    "# Sentence Lists\n",
    "test_sentence_text = []\n",
    "test_sentence_class = []\n",
    "test_sentence_list = []\n",
    "\n",
    "\n",
    "\n",
    "#action first party\n",
    "total_data_samples0 = []\n",
    "total_data_number0 = []\n",
    "total_data_label0 = []\n",
    "\n",
    "#Personal Info Type\n",
    "total_data_samples1 = []\n",
    "total_data_number1 = []\n",
    "total_data_label1 = []\n",
    "\n",
    "\n",
    "#Purpose\n",
    "total_data_samples2 = []\n",
    "total_data_number2 = []\n",
    "total_data_label2 = []\n",
    "\n",
    "\n",
    "#None\n",
    "total_data_samples3 = []\n",
    "total_data_number3 = []\n",
    "total_data_label3 = []\n",
    "\n",
    "#checking counts, we can remove them later\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "#checking counts, we can remove them later\n",
    "count_11 = 0\n",
    "count_22 = 0\n",
    "count_33 = 0\n",
    "\n",
    "\n",
    "# all the followint positives are to be counted if the sentences are in that particular class. \n",
    "# A sen_neg to be counted in any other circumstances\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "test_sen_actioFP = []\n",
    "test_sen_actioFP_class = []\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "test_sen_personalIT = []\n",
    "test_sen_personalIT_class = []\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "test_sen_purpose = []\n",
    "test_sen_purpose_class = []\n",
    "\n",
    "cnt = 0\n",
    "cnt0 = 0\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "cnt3 = 0\n",
    "choice = 0\n",
    "allFiles = allFiles[:85]\n",
    "\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "\n",
    "sen3_pos = 0\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "#     print(len(list(soup.descendants)))\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "#         print(element)\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "#                 print(len(string))\n",
    "                start_index.append(count)\n",
    "#                 print(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "\n",
    "for file in allFiles:\n",
    "    dictCollection = {\"Action First-Party\":[],\n",
    "                      \"Purpose\":[],\n",
    "                      \"Personal Information Type\":[],\n",
    "                      \"None\":[]\n",
    "                      }\n",
    "\n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    # df_tail = df.tail(1)[4]\n",
    "    # print(df_tail)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Test/', 1)[1]\n",
    "#     print(file)\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = 'Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "#     print(file_html)\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "#     print(len(indeces))\n",
    "#     print(len(ls))\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "            if parse_json[\"Action First-Party\"][\"endIndexInSegment\"] != -1:\n",
    "                count_11 += 1\n",
    "#                 total_data_samples0.append(parse_json[\"Action First-Party\"][\"selectedText\"])\n",
    "#                 total_data_number0.append(0)\n",
    "#                 total_data_label0.append(\"Action First-Party\")\n",
    "                str_index = parse_json[\"Action First-Party\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Action First-Party\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_1 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sentence_list.append([ls[index],\"Action_First-Party_positive\",\"positive\"])\n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Action_First-Party_positive\")\n",
    "                        sen0_pos += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1                        \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"pos\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                    else: \n",
    "                        test_sentence_list.append([ls[index],\"Action_First-Party_negative\",\"negative\"])\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1                                                \n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Action_First-Party_negative\")\n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                cnt0 = cnt0+1\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                count_22 += 1\n",
    "#                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "#                 total_data_number1.append(1)\n",
    "#                 total_data_label1.append(\"Personal Information Type\")                \n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_2 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "                        sen1_pos += 1\n",
    "                        sen0_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"pos\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                    else: \n",
    "                        test_sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1                                                \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                cnt1 = cnt1+1\n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                count_33 += 1                \n",
    "#                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "#                 total_data_number2.append(2)\n",
    "#                 total_data_label2.append(\"Purpose\")     \n",
    "                str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    count_3 += 1\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Purpose_positive\")\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1                        \n",
    "                        sen2_pos += 1\n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"pos\")\n",
    "                    else: \n",
    "                        test_sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "                        test_sentence_text.append(ls[index])\n",
    "                        test_sentence_class.append(\"Purpose_negative\")\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1                                                \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "# #             print(parse_json)\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "# #                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "# #                 total_data_number1.append(1)\n",
    "# #                 total_data_label1.append(\"Personal Information Type\") \n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "# #                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "# #                 total_data_number2.append(2)\n",
    "# #                 total_data_label2.append(\"Purpose\")\n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_3 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Purpose_positive\")\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         test_sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Purpose_negative\")\n",
    "#                         sen2_neg += 1\n",
    "#                 cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"User Choice/Control\":\n",
    "# #             choice = 1\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "# #                 test_total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "# # #                 print(parse_json[\"Personal Information Type\"][\"startIndexInSegment\"],parse_json[\"Personal Information Type\"][\"endIndexInSegment\"])\n",
    "# #                 total_data_number1.append(1)\n",
    "# #                 total_data_label1.append(\"Personal Information Type\")\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "# #                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "# #                 total_data_number2.append(2)\n",
    "# #                 total_data_label2.append(\"Purpose\")  \n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_3 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sentence_list.append([ls[index],\"Purpose_positive\",\"positive\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Purpose_positive\")\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         test_sentence_list.append([ls[index],\"Purpose_negative\",\"negative\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Purpose_negative\")\n",
    "#                         sen2_neg += 1\n",
    "#                 cnt2 = cnt2+1\n",
    "#         if df[5][i] == \"Data Retention\":\n",
    "# #             choice = 1\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "# #                 total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "# #                 total_data_number1.append(1)\n",
    "# #                 total_data_label1.append(\"Personal Information Type\")    \n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     count_2 += 1\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_positive\",\"positive\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_positive\")\n",
    "#                         sen1_pos += 1\n",
    "#                     else: \n",
    "#                         test_sentence_list.append([ls[index],\"Personal_Information_Type_negative\",\"negative\"])\n",
    "#                         test_sentence_text.append(ls[index])\n",
    "#                         test_sentence_class.append(\"Personal_Information_Type_negative\")\n",
    "#                         sen1_neg += 1\n",
    "#                 cnt1 = cnt1+1\n",
    "#         if choice==0:\n",
    "# #             print(\"practis is -->\", df[5][i])\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "# #             print(parse_json)\n",
    "# #             print(len(df[6][i]))\n",
    "# #             print(parse_json.keys())\n",
    "#             attributes = parse_json.keys()\n",
    "# #             print(attributes)\n",
    "#             for k in attributes:\n",
    "# #                 print(k)\n",
    "#                 if parse_json[k]['startIndexInSegment'] != -1:\n",
    "# #                     print(parse_json[k]['selectedText'])\n",
    "# #                     total_data_samples3.append(parse_json[k]['selectedText'])\n",
    "# #                     total_data_number3.append(3)\n",
    "# #                     total_data_label3.append(\"None\")\n",
    "#                     str_index = parse_json[k][\"startIndexInSegment\"]\n",
    "#                     end_index = parse_json[k][\"endIndexInSegment\"]\n",
    "#                     for index in range(len(ls)):\n",
    "#                         count_3 += 1\n",
    "#                         if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                            (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                            (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                            (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                             test_sentence_list.append([ls[index],\"None_positive\",\"positive\"])\n",
    "#                             test_sentence_text.append(ls[index])\n",
    "#                             test_sentence_class.append(\"none\")\n",
    "#                             sen3_pos += 1\n",
    "                        \n",
    "#                     cnt3 = cnt3+1\n",
    "\n",
    "                \n",
    "# print(\"----- check counts\")                \n",
    "# print(count_1, count_11)\n",
    "# print(count_2, count_22)\n",
    "# print(count_3, count_33)                \n",
    "                \n",
    "                \n",
    "                \n",
    "print(\"----- postive and -ve sentences\")                \n",
    "print(sen0_pos,sen0_neg)\n",
    "print(sen1_pos,sen1_neg)\n",
    "print(sen2_pos,sen2_neg)\n",
    "print(len(test_sentence_list))\n",
    "\n",
    "\n",
    "print(\"----- postive and -ve sentences count\")                \n",
    "print(len(test_sen_actioFP),len(test_sen_actioFP_class))\n",
    "print(len(test_sen_personalIT),len(test_sen_personalIT_class))\n",
    "print(len(test_sen_purpose),len(test_sen_purpose_class))\n",
    "print(len(test_sentence_list))\n",
    "\n",
    "\n",
    "\n",
    "# print(\"---\")\n",
    "# print(cnt0)\n",
    "# print(cnt1)\n",
    "# print(cnt2)\n",
    "# print(cnt3)\n",
    "# print(\"--\")\n",
    "# print(cnt0+cnt1+cnt2+cnt3)\n",
    "# # print(len(total_data_samples0))\n",
    "# # print(len(total_data_samples1))\n",
    "# # print(len(total_data_samples2))\n",
    "# # print(len(total_data_samples3)) # 22536\n",
    "\n",
    "# print(len(test_sentence_text))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=1000)\n",
    "X_train_counts = count_vect.fit_transform(sen_actioFP)\n",
    "X_train_counts\n",
    "count_vect.get_feature_names()\n",
    "count_vect.get_stop_words()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(sen_actioFP, sen_actioFP_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99648114167403468"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = text_clf.predict(test_sen_actioFP)\n",
    "np.mean(predicted == test_sen_actioFP_class)\n",
    "#0.99706813025198082\n",
    "#0.99648114167403468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       1.00      1.00      1.00    673428\n",
      "        pos       0.11      0.05      0.07      1791\n",
      "\n",
      "avg / total       1.00      1.00      1.00    675219\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[672759,    669],\n",
       "       [  1707,     84]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_sen_actioFP_class, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_sen_actioFP_class, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 83], [83, 179], [179, 282], [282, 827], [827, 934], [934, 1064], [1064, 1176], [1176, 1230], [1230, 1427], [1427, 1652], [1652, 1750], [1750, 1883], [1883, 2000], [2000, 2104], [2104, 2235], [2235, 2300], [2300, 2373], [2373, 2501], [2501, 2591], [2591, 2710], [2710, 2853], [2853, 3011], [3011, 3166], [3166, 3298]]\n"
     ]
    }
   ],
   "source": [
    "# Produce two tables: \n",
    "# one with counts of sought text spans and \n",
    "# one with counts of sentences, labeled positive and negative, for the sought attributes.\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "#     print(len(list(soup.descendants)))\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "#         print(element)\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "#                 print(len(string))\n",
    "                start_index.append(count)\n",
    "#                 print(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "for file in allFiles:\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "#         print(count)\n",
    "#         print(l)\n",
    "        count = count+len(l)\n",
    "print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action_First-Party_negative',\n",
       " 'Action_First-Party_positive',\n",
       " 'Personal_Information_Type_negative',\n",
       " 'Personal_Information_Type_positive',\n",
       " 'Purpose_negative',\n",
       " 'Purpose_positive',\n",
       " 'none'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_sentence_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action_First-Party_negative',\n",
       " 'Action_First-Party_positive',\n",
       " 'Personal_Information_Type_negative',\n",
       " 'Personal_Information_Type_positive',\n",
       " 'Purpose_negative',\n",
       " 'Purpose_positive',\n",
       " 'none'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sentence_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
