{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-606555d7f122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mnumber_of_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;31m#     print(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Test'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#action first party\n",
    "total_data_samples0 = []\n",
    "total_data_number0 = []\n",
    "total_data_label0 = []\n",
    "\n",
    "#Personal Info Type\n",
    "total_data_samples1 = []\n",
    "total_data_number1 = []\n",
    "total_data_label1 = []\n",
    "\n",
    "\n",
    "#Purpose\n",
    "total_data_samples2 = []\n",
    "total_data_number2 = []\n",
    "total_data_label2 = []\n",
    "\n",
    "\n",
    "#None\n",
    "total_data_samples3 = []\n",
    "total_data_number3 = []\n",
    "total_data_label3 = []\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "cnt0 = 0\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "cnt3 = 0\n",
    "choice = 0\n",
    "allFiles = allFiles[:65]\n",
    "\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "#     print(len(list(soup.descendants)))\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "#         print(element)\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "#                 print(len(string))\n",
    "                start_index.append(count)\n",
    "#                 print(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "sentence_list = []\n",
    "\n",
    "for file in allFiles:\n",
    "    dictCollection = {\"Action First-Party\":[],\n",
    "                      \"Purpose\":[],\n",
    "                      \"Personal Information Type\":[],\n",
    "                      \"None\":[]\n",
    "                      }\n",
    "\n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    # df_tail = df.tail(1)[4]\n",
    "    # print(df_tail)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Test/', 1)[1]\n",
    "#     print(file)\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = 'Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "    print(file_html)\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "    print(len(indeces))\n",
    "    print(len(ls))\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_segments-1):\n",
    "#         print(i)\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "#             print(parse_json)\n",
    "            if parse_json[\"Action First-Party\"][\"endIndexInSegment\"] != -1:\n",
    "#                 print(\"ActionFirst Party\",parse_json[\"Action First-Party\"][\"startIndexInSegment\"],parse_json[\"Action First-Party\"][\"endIndexInSegment\"])\n",
    "                total_data_samples0.append(parse_json[\"Action First-Party\"][\"selectedText\"])\n",
    "                total_data_number0.append(0)\n",
    "                total_data_label0.append(\"Action First-Party\")\n",
    "                str_index = parse_json[\"Action First-Party\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Action First-Party\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Action First-Party\",\"positive\"])\n",
    "                        sen0_pos += 1\n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Action First-Party\",\"negative\"])\n",
    "                        sen0_neg += 1\n",
    "                cnt0 = cnt0+1\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 print(\"Personal Information Type\",parse_json[\"Personal Information Type\"][\"startIndexInSegment\"],parse_json[\"Personal Information Type\"][\"endIndexInSegment\"])\n",
    "                total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                total_data_number1.append(1)\n",
    "                total_data_label1.append(\"Personal Information Type\")                \n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Personal Information Type\",\"positive\"])\n",
    "                        sen1_pos += 1\n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Personal Information Type\",\"negative\"])\n",
    "                        sen1_neg += 1\n",
    "                cnt1 = cnt1+1\n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 print(\"Purpose\",parse_json[\"Purpose\"][\"startIndexInSegment\"],parse_json[\"Purpose\"][\"endIndexInSegment\"])\n",
    "                total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "                total_data_number2.append(2)\n",
    "                total_data_label2.append(\"Purpose\")     \n",
    "                str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sentence_list.append([ls[index],\"Purpose\",\"positive\"])\n",
    "                        sen2_pos += 1\n",
    "                    else: \n",
    "                        sentence_list.append([ls[index],\"Purpose\",\"negative\"])\n",
    "                        sen2_neg += 1\n",
    "                cnt2 = cnt2+1\n",
    "        if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "#             print(parse_json)\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                total_data_number1.append(1)\n",
    "                total_data_label1.append(\"Personal Information Type\")                \n",
    "                cnt1 = cnt1+1\n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "                total_data_number2.append(2)\n",
    "                total_data_label2.append(\"Purpose\")     \n",
    "                cnt2 = cnt2+1\n",
    "        if df[5][i] == \"User Choice/Control\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                print(parse_json[\"Personal Information Type\"][\"startIndexInSegment\"],parse_json[\"Personal Information Type\"][\"endIndexInSegment\"])\n",
    "                total_data_number1.append(1)\n",
    "                total_data_label1.append(\"Personal Information Type\")                \n",
    "                cnt1 = cnt1+1\n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "                total_data_number2.append(2)\n",
    "                total_data_label2.append(\"Purpose\")     \n",
    "                cnt2 = cnt2+1\n",
    "        if df[5][i] == \"Data Retention\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                total_data_samples1.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                total_data_number1.append(1)\n",
    "                total_data_label1.append(\"Personal Information Type\")                \n",
    "                cnt1 = cnt1+1\n",
    "        if choice==0:\n",
    "#             print(\"practis is -->\", df[5][i])\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "#             print(parse_json)\n",
    "#             print(len(df[6][i]))\n",
    "#             print(parse_json.keys())\n",
    "            attributes = parse_json.keys()\n",
    "#             print(attributes)\n",
    "            for k in attributes:\n",
    "#                 print(k)\n",
    "                if parse_json[k]['startIndexInSegment'] != -1:\n",
    "#                     print(parse_json[k]['selectedText'])\n",
    "                    total_data_samples3.append(parse_json[k]['selectedText'])\n",
    "                    total_data_number3.append(3)\n",
    "                    total_data_label3.append(\"None\")  \n",
    "                    cnt3 = cnt3+1\n",
    "                    \n",
    "print(sen0_pos,sen0_neg)\n",
    "print(sen1_pos,sen1_neg)\n",
    "print(sen2_pos,sen2_neg)\n",
    "\n",
    "# print(sentence_list)    \n",
    "print(\"---\")\n",
    "print(cnt0)\n",
    "print(cnt1)\n",
    "print(cnt2)\n",
    "print(cnt3)\n",
    "print(\"--\")\n",
    "print(cnt0+cnt1+cnt2+cnt3)\n",
    "print(len(total_data_samples0))\n",
    "print(len(total_data_samples1))\n",
    "print(len(total_data_samples2))\n",
    "print(len(total_data_samples3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
