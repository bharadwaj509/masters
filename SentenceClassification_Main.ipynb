{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- postive and -ve sentences\n",
      "4464 1384080\n",
      "5301 1383243\n",
      "5356 1383188\n"
     ]
    }
   ],
   "source": [
    "# the original code is in the SentenceClassification.ipytn file. I am eliminating many variables in this file.\n",
    "\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Train'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "\n",
    "allFiles = allFiles[:65]\n",
    "\n",
    "\n",
    "# all the followint positives are to be counted if the sentences are in that particular class. \n",
    "# A sen_neg to be counted in any other circumstances\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_actioFP = []\n",
    "sen_actioFP_class = []\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_personalIT = []\n",
    "sen_personalIT_class = []\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "sen_purpose = []\n",
    "sen_purpose_class = []\n",
    "\n",
    "sen3_pos = 0\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head tag\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "                start_index.append(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "for file in allFiles:\n",
    "    \n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Train/', 1)[1]\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = 'Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "\n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "            # parsing and fetching the text related to \"Action First Party\"            \n",
    "            if parse_json[\"Action First-Party\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Action First-Party\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Action First-Party\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"pos\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")\n",
    "                        sen0_pos += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                    else: \n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")\n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "            # parsing and fetching the text related to \"Personal Information Type\"                        \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"pos\")                        \n",
    "                        sen_purpose_class.append(\"neg\")  \n",
    "                        sen0_neg += 1\n",
    "                        sen1_pos += 1\n",
    "                        sen2_neg += 1\n",
    "                    else: \n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")  \n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "            # parsing and fetching the text related to \"Purpose\"                \n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                choice = 1            \n",
    "                str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"pos\")    \n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_pos += 1\n",
    "                    else: \n",
    "                        sen_actioFP.append(ls[index])\n",
    "                        sen_personalIT.append(ls[index])\n",
    "                        sen_purpose.append(ls[index])\n",
    "                        sen_actioFP_class.append(\"neg\")                        \n",
    "                        sen_personalIT_class.append(\"neg\")                        \n",
    "                        sen_purpose_class.append(\"neg\")                        \n",
    "                        sen0_neg += 1\n",
    "                        sen1_neg += 1\n",
    "                        sen2_neg += 1\n",
    "                                \n",
    "#         if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):                    \n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_pos += 1\n",
    "#                         sen2_neg += 1\n",
    "#                     else: \n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1                        \n",
    "#                         sen2_neg += 1\n",
    "\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "#                 total_data_number2.append(2)\n",
    "#                 total_data_label2.append(\"Purpose\") \n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1                        \n",
    "#                         sen2_neg += 1\n",
    "\n",
    "#         if df[5][i] == \"User Choice/Control\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_pos += 1\n",
    "#                         sen2_neg += 1\n",
    "#                     else: \n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1                        \n",
    "#                         sen2_neg += 1\n",
    "            \n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1\n",
    "#                         sen2_pos += 1\n",
    "#                     else: \n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1                        \n",
    "#                         sen2_neg += 1\n",
    "\n",
    "#         if df[5][i] == \"Data Retention\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_pos += 1                        \n",
    "#                         sen2_neg += 1\n",
    "#                     else: \n",
    "#                         sen0_neg += 1\n",
    "#                         sen1_neg += 1                        \n",
    "#                         sen2_neg += 1\n",
    "                            \n",
    "                            \n",
    "print(\"----- postive and -ve sentences\")                \n",
    "# print(len(sen_actioFP),len(sen_actioFP_class))\n",
    "# print(len(sen_personalIT),len(sen_personalIT_class))\n",
    "# print(len(sen_purpose),len(sen_purpose_class))\n",
    "# print(len(sentence_list))\n",
    "\n",
    "\n",
    "print(sen0_pos, sen0_neg)\n",
    "print(sen1_pos, sen1_neg)\n",
    "print(sen2_pos, sen2_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of all files 25\n",
      "----- postive and -ve sentences count\n",
      "1791 673428\n",
      "2286 672933\n",
      "2175 673044\n"
     ]
    }
   ],
   "source": [
    "### Extraacing the test data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Test'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "print(\"len of all files\", len(allFiles))\n",
    "\n",
    "\n",
    "# all the followint positives are to be counted if the sentences are in that particular class. \n",
    "# A sen_neg to be counted in any other circumstances\n",
    "test_sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "test_sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "test_sen_actioFP = []\n",
    "test_sen_actioFP_class = []\n",
    "\n",
    "test_sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "test_sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "test_sen_personalIT = []\n",
    "test_sen_personalIT_class = []\n",
    "\n",
    "test_sen2_pos = 0 # purpose no. of sentence negatives\n",
    "test_sen2_neg = 0 # purpose no. of sentence negatives\n",
    "test_sen_purpose = []\n",
    "test_sen_purpose_class = []\n",
    "\n",
    "choice = 0\n",
    "allFiles = allFiles[:25]\n",
    "\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "                start_index.append(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "\n",
    "for file in allFiles:\n",
    "    \n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Test/', 1)[1]\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = 'Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            choice = 1\n",
    "            parse_json = json.loads(str(df[6][i]))\n",
    "\n",
    "            if parse_json[\"Action First-Party\"][\"endIndexInSegment\"] != -1:\n",
    "                str_index = parse_json[\"Action First-Party\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Action First-Party\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sen0_pos += 1\n",
    "                        test_sen1_neg += 1\n",
    "                        test_sen2_neg += 1                        \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"pos\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                    else: \n",
    "                        test_sen0_neg += 1\n",
    "                        test_sen1_neg += 1\n",
    "                        test_sen2_neg += 1                                                \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sen1_pos += 1\n",
    "                        test_sen0_neg += 1\n",
    "                        test_sen2_neg += 1\n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"pos\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                    else: \n",
    "                        test_sen0_neg += 1\n",
    "                        test_sen1_neg += 1\n",
    "                        test_sen2_neg += 1                                                \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "                \n",
    "            if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "                str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "                for index in range(len(ls)):\n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "                        test_sen0_neg += 1\n",
    "                        test_sen1_neg += 1                        \n",
    "                        test_sen2_pos += 1\n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"pos\")\n",
    "                    else: \n",
    "                        test_sen0_neg += 1\n",
    "                        test_sen1_neg += 1\n",
    "                        test_sen2_neg += 1                                                \n",
    "                        test_sen_actioFP.append(ls[index])\n",
    "                        test_sen_personalIT.append(ls[index])\n",
    "                        test_sen_purpose.append(ls[index])\n",
    "                        test_sen_actioFP_class.append(\"neg\")                        \n",
    "                        test_sen_personalIT_class.append(\"neg\")                        \n",
    "                        test_sen_purpose_class.append(\"neg\")\n",
    "#         if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_pos += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "#                     else: \n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "\n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 total_data_samples2.append(parse_json[\"Purpose\"][\"selectedText\"])\n",
    "#                 total_data_number2.append(2)\n",
    "#                 total_data_label2.append(\"Purpose\") \n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_pos += 1\n",
    "#                     else: \n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "\n",
    "#         if df[5][i] == \"User Choice/Control\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_pos += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "#                     else: \n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "            \n",
    "#             if parse_json[\"Purpose\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Purpose\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Purpose\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_pos += 1\n",
    "#                     else: \n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "\n",
    "#         if df[5][i] == \"Data Retention\":\n",
    "#             parse_json = json.loads(str(df[6][i]))\n",
    "#             if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1:\n",
    "#                 choice = 1\n",
    "#                 str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "#                 end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "#                 for index in range(len(ls)):\n",
    "#                     if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "#                        (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "#                        (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):\n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_pos += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "#                     else: \n",
    "#                         test_sen0_neg += 1\n",
    "#                         test_sen1_neg += 1                        \n",
    "#                         test_sen2_neg += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"----- postive and -ve sentences count\")                \n",
    "# print(len(test_sen_actioFP),len(test_sen_actioFP_class))\n",
    "# print(len(test_sen_personalIT),len(test_sen_personalIT_class))\n",
    "# print(len(test_sen_purpose),len(test_sen_purpose_class))\n",
    "\n",
    "\n",
    "print(test_sen0_pos,test_sen0_neg)\n",
    "print(test_sen1_pos,test_sen1_neg)\n",
    "print(test_sen2_pos,test_sen2_neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.89      0.64       100\n",
      "          1       0.50      0.11      0.18       100\n",
      "\n",
      "avg / total       0.50      0.50      0.41       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[89, 11],\n",
       "       [89, 11]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "### randomly choosing -ve sentences from the huge list\n",
    "### We shall try to maximizze the prediction\n",
    "\n",
    "### separating the +ve and -ve sentences\n",
    "classes = [1]*4464\n",
    "classes[4464:8928] = [0]*4464\n",
    "final_action_FP = sen_actioFP[:4464]\n",
    "action_FP_neg = sen_actioFP[4465:]\n",
    "\n",
    "final_list = []\n",
    "max_result_list = []\n",
    "\n",
    "final_list = np.random.choice(action_FP_neg, 4464)\n",
    "\n",
    "ls = final_action_FP\n",
    "ls.extend(final_list)\n",
    "\n",
    "# performing the training here\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(ls, classes)\n",
    "\n",
    "### performing the testing here and we will iterate the process and save the best results\n",
    "test_set = test_sen_actioFP[:100]+test_sen_actioFP[1791:1891]\n",
    "test_classes = [1]*100 + [0]*100\n",
    "predicted = text_clf.predict(test_set)\n",
    "print(np.mean(predicted == test_classes))\n",
    "\n",
    "print(metrics.classification_report(test_classes, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_classes, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.88      0.64       100\n",
      "          1       0.50      0.12      0.19       100\n",
      "\n",
      "avg / total       0.50      0.50      0.42       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[88, 12],\n",
       "       [88, 12]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list = []\n",
    "max_result_list = []\n",
    "\n",
    "final_list1 = np.random.choice(action_FP_neg, 4464)\n",
    "\n",
    "ls1 = final_action_FP\n",
    "ls1.extend(final_list1)\n",
    "\n",
    "\n",
    "# performing the training here\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(ls1, classes)\n",
    "\n",
    "### performing the testing here and we will iterate the process and save the best results\n",
    "\n",
    "predicted = text_clf.predict(test_set)\n",
    "print(np.mean(predicted == test_classes))\n",
    "\n",
    "print(metrics.classification_report(test_classes, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_classes, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.91      0.65       100\n",
      "          1       0.55      0.11      0.18       100\n",
      "\n",
      "avg / total       0.53      0.51      0.42       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[91,  9],\n",
       "       [89, 11]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [1]*4464\n",
    "classes[4464:8928] = [0]*4464\n",
    "final_action_FP = sen_actioFP[:4464]\n",
    "action_FP_neg = sen_actioFP[4465:]\n",
    "\n",
    "final_list = []\n",
    "max_result_list = []\n",
    "\n",
    "final_list2 = np.random.choice(action_FP_neg, 4464)\n",
    "\n",
    "ls2 = final_action_FP\n",
    "ls2.extend(final_list2)\n",
    "\n",
    "\n",
    "# performing the training here\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(ls2, classes)\n",
    "\n",
    "### performing the testing here and we will iterate the process and save the best results\n",
    "\n",
    "predicted = text_clf.predict(test_set)\n",
    "print(np.mean(predicted == test_classes))\n",
    "\n",
    "print(metrics.classification_report(test_classes, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_classes, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "final_list1 = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    final_list1.append(np.random.choice(action_FP_neg, 4464).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464\n"
     ]
    }
   ],
   "source": [
    "final_list5 = []\n",
    "final_list5.append(np.random.choice(action_FP_neg, 4464).tolist())\n",
    "print(len(final_list5[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.88      0.64       100\n",
      "          1       0.48      0.11      0.18       100\n",
      "\n",
      "avg / total       0.49      0.49      0.41       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.86      0.63       100\n",
      "          1       0.50      0.14      0.22       100\n",
      "\n",
      "avg / total       0.50      0.50      0.43       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.91      0.65       100\n",
      "          1       0.50      0.09      0.15       100\n",
      "\n",
      "avg / total       0.50      0.50      0.40       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.90      0.64       100\n",
      "          1       0.50      0.10      0.17       100\n",
      "\n",
      "avg / total       0.50      0.50      0.40       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.86      0.63       100\n",
      "          1       0.50      0.14      0.22       100\n",
      "\n",
      "avg / total       0.50      0.50      0.43       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.88      0.64       100\n",
      "          1       0.52      0.13      0.21       100\n",
      "\n",
      "avg / total       0.51      0.51      0.42       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.89      0.64       100\n",
      "          1       0.54      0.13      0.21       100\n",
      "\n",
      "avg / total       0.52      0.51      0.43       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.88      0.64       100\n",
      "          1       0.48      0.11      0.18       100\n",
      "\n",
      "avg / total       0.49      0.49      0.41       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.89      0.64       100\n",
      "          1       0.50      0.11      0.18       100\n",
      "\n",
      "avg / total       0.50      0.50      0.41       200\n",
      "\n",
      "-----\n",
      "4464 4464\n",
      "len is 1 4464 4464\n",
      "len is 2 8928\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.90      0.64       100\n",
      "          1       0.50      0.10      0.17       100\n",
      "\n",
      "avg / total       0.50      0.50      0.40       200\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "final_action_FP = sen_actioFP[:4464]\n",
    "\n",
    "for i in range(10):\n",
    "    ls = []\n",
    "    ls = final_action_FP\n",
    "    print(len(final_action_FP), len(ls))\n",
    "    print(\"len is 1\", len(ls), len(final_action_FP))\n",
    "    ls.extend(final_list1[i])\n",
    "    print(\"len is 2\", len(ls))\n",
    "    # performing the training here\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "    text_clf = text_clf.fit(ls, classes)\n",
    "\n",
    "    ### performing the testing here and we will iterate the process and save the best results\n",
    "\n",
    "    predicted = text_clf.predict(test_set)\n",
    "    \n",
    "    print(np.mean(predicted == test_classes))\n",
    "    print(metrics.classification_report(test_classes, predicted))\n",
    "    \n",
    "    metrics.confusion_matrix(test_classes, predicted)\n",
    "    ls[4464:8928] = []\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = [\"how we use and disclose that information.\"]\n",
    "sample_class = [\"neg\"]\n",
    "import numpy as np\n",
    "predicted = text_clf.predict(sample_test)\n",
    "np.mean(predicted == sample_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10602\n",
      "0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.85      0.62       100\n",
      "          1       0.46      0.13      0.20       100\n",
      "\n",
      "avg / total       0.48      0.49      0.41       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85, 15],\n",
       "       [87, 13]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "### randomly choosing -ve sentences from the huge list\n",
    "### We shall try to maximizze the prediction\n",
    "\n",
    "### separating the +ve and -ve sentences\n",
    "classes = [1]*5301\n",
    "classes[5301:10602] = [0]*5301\n",
    "print(len(classes))\n",
    "final_personalIT = sen_personalIT[:5301]\n",
    "personalIT_neg = sen_personalIT[5302:]\n",
    "\n",
    "final_list = []\n",
    "max_result_list = []\n",
    "\n",
    "final_list = np.random.choice(personalIT_neg, 5301)\n",
    "\n",
    "ls_personal = final_personalIT\n",
    "ls_personal.extend(final_list)\n",
    "\n",
    "# performing the training here\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(ls_personal, classes)\n",
    "\n",
    "### performing the testing here and we will iterate the process and save the best results\n",
    "test_set = test_sen_personalIT[:100]+test_sen_personalIT[2286:2386]\n",
    "test_classes = [1]*100 + [0]*100\n",
    "predicted = text_clf.predict(test_set)\n",
    "print(np.mean(predicted == test_classes))\n",
    "\n",
    "print(metrics.classification_report(test_classes, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_classes, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "final_list2 = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    final_list2.append(np.random.choice(personalIT_neg, 5301).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n",
      "5301\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(final_list2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n",
      "5301 5301\n",
      "len is 1 5301 5301\n",
      "len is 2 10602\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       100\n",
      "          1       0.50      0.99      0.66       100\n",
      "\n",
      "avg / total       0.50      0.50      0.34       200\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "final_personalIT = sen_personalIT[:5301]\n",
    "\n",
    "for i in range(10):\n",
    "    ls2 = []\n",
    "    ls2 = final_personalIT\n",
    "    print(len(final_personalIT), len(ls2))\n",
    "    print(\"len is 1\", len(ls2), len(final_personalIT))\n",
    "    ls2.extend(final_list2[i])\n",
    "    print(\"len is 2\", len(ls2))\n",
    "    # performing the training here\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "    text_clf = text_clf.fit(ls2, classes)\n",
    "\n",
    "    ### performing the testing here and we will iterate the process and save the best results\n",
    "\n",
    "    predicted = text_clf.predict(test_set)\n",
    "    \n",
    "    print(np.mean(predicted == test_classes))\n",
    "    print(metrics.classification_report(test_classes, predicted))\n",
    "    \n",
    "    metrics.confusion_matrix(test_classes, predicted)\n",
    "    ls2[5301:10602] = []\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10712\n",
      "0.495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.86      0.63       100\n",
      "          1       0.48      0.13      0.20       100\n",
      "\n",
      "avg / total       0.49      0.49      0.42       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[86, 14],\n",
       "       [87, 13]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "### randomly choosing -ve sentences from the huge list\n",
    "### We shall try to maximizze the prediction\n",
    "\n",
    "### separating the +ve and -ve sentences\n",
    "classes = [1]*5356\n",
    "classes[5356:10712] = [0]*5356\n",
    "print(len(classes))\n",
    "final_purpose = sen_purpose[:5356]\n",
    "purpose_neg = sen_purpose[5357:]\n",
    "\n",
    "final_list3 = []\n",
    "\n",
    "final_list3 = np.random.choice(purpose_neg, 5356)\n",
    "\n",
    "ls_personal = final_purpose\n",
    "ls_personal.extend(final_list3)\n",
    "\n",
    "# performing the training here\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(ls_personal, classes)\n",
    "\n",
    "### performing the testing here and we will iterate the process and save the best results\n",
    "test_set = test_sen_purpose[:100]+test_sen_purpose[2175:2275]\n",
    "test_classes = [1]*100 + [0]*100\n",
    "predicted = text_clf.predict(test_set)\n",
    "print(np.mean(predicted == test_classes))\n",
    "\n",
    "print(metrics.classification_report(test_classes, predicted))\n",
    "\n",
    "metrics.confusion_matrix(test_classes, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
