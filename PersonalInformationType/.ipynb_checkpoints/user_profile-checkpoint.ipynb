{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6532\n",
      "6532\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "objects = []\n",
    "with (open(\"noun_phrase_results/entities_test\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "print len(objects[0])            \n",
    "test = objects[0]\n",
    "print len(test)\n",
    "entities_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11035\n",
      "11035\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "objects_train = []\n",
    "with (open(\"noun_phrase_results/entities_train1\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects_train.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "print len(objects_train[0])            \n",
    "original_test = objects_train[0]\n",
    "print len(original_test)\n",
    "entities_train = original_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the contact sentences from Personal Information Type\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# the original code is in the SentenceClassification.ipytn file. I am eliminating many variables in this file.\n",
    "# This file is copied from the SentenceClassification_main file.\n",
    "# In here we are trying to extract the data related to the value \"Health\" in the category Personal Information Type\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'../Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Train'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "allFiles = allFiles[:65]\n",
    "\n",
    "\n",
    "# all the followint positives are to be counted if the sentences are in that particular class. \n",
    "# A sen_neg to be counted in any other circumstances\n",
    "sen0_pos = 0 # action_first_party no. of sentence positives\n",
    "sen0_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_actioFP = []\n",
    "sen_actioFP_class = []\n",
    "\n",
    "sen1_pos = 0 # Personal Information Type no. of sentence positives\n",
    "sen1_neg = 0 # action_first_party no. of sentence negatives\n",
    "sen_personalIT = []\n",
    "sen_personalIT_class = []\n",
    "\n",
    "sen2_pos = 0 # purpose no. of sentence negatives\n",
    "sen2_neg = 0 # purpose no. of sentence negatives\n",
    "sen_purpose = []\n",
    "sen_purpose_class = []\n",
    "\n",
    "sen_Others = []\n",
    "\n",
    "firstParty = []\n",
    "thirdParty = []\n",
    "dataRetention = []\n",
    "userControl = []\n",
    "\n",
    "span_contact = []\n",
    "\n",
    "sen3_pos = 0\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head tag\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "                start_index.append(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "for file in allFiles:\n",
    "    \n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Train/', 1)[1]\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = '../Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "\n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                span_contact.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        firstParty.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "\n",
    "        if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                span_contact.append(parse_json[\"Personal Information Type\"][\"selectedText\"])\n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        thirdParty.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "        if df[5][i] == \"User Choice/Control\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                span_contact.append(parse_json[\"Personal Information Type\"][\"selectedText\"])                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])                        \n",
    "                        userControl.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "        if df[5][i] == \"Data Retention\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                span_contact.append(parse_json[\"Personal Information Type\"][\"selectedText\"])                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        dataRetention.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "print(\"len of the contact sentences from Personal Information Type\")\n",
    "print(len(sen_personalIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 902\n"
     ]
    }
   ],
   "source": [
    "# extracting the named entities form the annotated sets in the training dataset\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from nltk.tree import Tree\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "train_list = []\n",
    "train = []\n",
    "for annot in sen_personalIT:\n",
    "    output = nlp.annotate(str(annot[1]), properties={'annotators': 'tokenize,ssplit,pos,depparse,parse', 'outputFormat': 'json'})\n",
    "#     print(output['sentences'][0]['parse'])\n",
    "    parsestr=output['sentences'][0]['parse']\n",
    "    for i in Tree.fromstring(parsestr).subtrees():\n",
    "        if i.label() == 'NP':\n",
    "            string = \"\"\n",
    "            for leaf in i.leaves():\n",
    "                if str(leaf)==',':\n",
    "                    string += str(leaf)\n",
    "                else:\n",
    "                    string += \" \"+str(leaf)\n",
    "#             print string.strip()\n",
    "            train_list.append(string.strip())\n",
    "                \n",
    "train = list(set(train_list))\n",
    "print len(train), len(train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "with open('noun_phrase_results/health/entities_train_personalIT_location_csv.csv', 'wb') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for i in Counter(train_list):\n",
    "        wr.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "10946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print len(set(train) & set(entities_train))\n",
    "entities_train =  list(set(entities_train) - (set(train) & set(entities_train)))\n",
    "print len(entities_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ls = random.sample(xrange(len(entities_train)), len(train))\n",
    "print len(ls)\n",
    "\n",
    "extracted_train = []\n",
    "for i in ls:\n",
    "    extracted_train.append(entities_train[i])\n",
    "\n",
    "print len(extracted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the contact sentences from Personal Information Type for test data\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "# the original code is in the SentenceClassification.ipytn file. I am eliminating many variables in this file.\n",
    "# This file is copied from the SentenceClassification_main file.\n",
    "# In here we are trying to extract the data related to the value \"Health\" in the category Personal Information Type\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import nltk.data\n",
    "\n",
    "path = r'Plain_Html'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.html\")\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "path = r'Test'  # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "allFiles = allFiles[:65]\n",
    "\n",
    "firstParty_test = []\n",
    "thirdParty_test = []\n",
    "dataRetention_test = []\n",
    "userControl_test = []\n",
    "\n",
    "sen_personalIT_test = []\n",
    "sen_personalIT = []\n",
    "\n",
    "def html_to_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    html_report_part1 = open(html,'r')\n",
    "    soup = BeautifulSoup(html_report_part1, 'html.parser')\n",
    "    # Ignore anything in head tag\n",
    "    text = []\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for element in soup.descendants:\n",
    "        # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "        count = 0;\n",
    "        if type(element) == NavigableString:\n",
    "            # We use the assumption that other tags can't be inside a script or style\n",
    "            if element.parent.name in ('script', 'style'):\n",
    "                continue\n",
    "\n",
    "            # remove any multiple and leading/trailing whitespace\n",
    "            string = ' '.join(element.string.split())\n",
    "            if string:\n",
    "                if element.parent.name == 'a':\n",
    "                    a_tag = element.parent\n",
    "                    # replace link text with the link\n",
    "                    string = a_tag['href']\n",
    "                    # concatenate with any non-empty immediately previous string\n",
    "                    if (    type(a_tag.previous_sibling) == NavigableString and\n",
    "                            a_tag.previous_sibling.string.strip() ):\n",
    "                        text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                elif element.previous_sibling and element.previous_sibling.name == 'a':\n",
    "                    text[-1] = text[-1] + ' ' + string\n",
    "                    continue\n",
    "                elif element.parent.name == 'p':\n",
    "                    # Add extra paragraph formatting newline\n",
    "                    string = '\\n' + string\n",
    "                text += [string]\n",
    "                start_index.append(count)\n",
    "    doc = '\\n'.join(text)\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "for file in allFiles:\n",
    "    \n",
    "    df = pd.read_csv(file, thousands=',', header=None)\n",
    "    len(df)\n",
    "    number_of_segments = len(df) + 1\n",
    "\n",
    "    file = file.split('Test/', 1)[1]\n",
    "\n",
    "    ### beautifulsuop on html doc\n",
    "    file_html = '../Plain_Html/'+file\n",
    "    file_html = file_html.split('csv', 1)[0]\n",
    "    file_html = file_html+'html'\n",
    "    ls = []\n",
    "    indeces = []\n",
    "    data = html_to_text(file_html)\n",
    "    ls = tokenizer.tokenize(data)\n",
    "    count = 0\n",
    "    for l in ls:\n",
    "        indeces.append([count,count+len(l)])\n",
    "        count = count+len(l)\n",
    "\n",
    "    for i in range(number_of_segments-1):\n",
    "        choice = 0 #whether the sentence is from one of the following categories\n",
    "        if df[5][i] == \"First Party Collection/Use\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        firstParty_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "        if df[5][i] == \"Third Party Sharing/Collection\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        thirdParty_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "        if df[5][i] == \"User Choice/Control\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])                        \n",
    "                        userControl_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "        \n",
    "        if df[5][i] == \"Data Retention\":\n",
    "            parse_json = json.loads(str(df[6][i]))            \n",
    "            if parse_json[\"Personal Information Type\"][\"endIndexInSegment\"] != -1 and parse_json[\"Personal Information Type\"][\"value\"]==\"User profile\":\n",
    "                choice = 1\n",
    "                str_index = parse_json[\"Personal Information Type\"][\"startIndexInSegment\"]\n",
    "                end_index = parse_json[\"Personal Information Type\"][\"endIndexInSegment\"]\n",
    "                \n",
    "                for index in range(len(ls)):\n",
    "                    parsed_sen = ls[index].replace(\"/\\n|||-\",\"\")                        \n",
    "                    parsed_sen = ls[index].replace(\"|||\",\"\") \n",
    "                    if((str_index > indeces[index][0] and end_index < indeces[index][1]) or \n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][1]) or\n",
    "                       (str_index < indeces[index][0] and end_index > indeces[index][0] and end_index < indeces[index][1]) or\n",
    "                       (str_index > indeces[index][0] and str_index < indeces[index][1] and end_index > indeces[index][1])):                        \n",
    "                        sen_personalIT_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        dataRetention_test.append([parsed_sen,parse_json[\"Personal Information Type\"][\"selectedText\"]])\n",
    "                        \n",
    "print(\"len of the contact sentences from Personal Information Type for test data\")\n",
    "print len(sen_personalIT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772\n"
     ]
    }
   ],
   "source": [
    "test_pos1 = []\n",
    "for annot in sen_personalIT_test:\n",
    "    output = nlp.annotate(str(annot[1]), properties={'annotators': 'tokenize,ssplit,pos,depparse,parse', 'outputFormat': 'json'})\n",
    "#     print(output['sentences'][0]['parse'])\n",
    "    parsestr=output['sentences'][0]['parse']\n",
    "    for i in Tree.fromstring(parsestr).subtrees():\n",
    "        if i.label() == 'NP':\n",
    "            string = \"\"\n",
    "            for leaf in i.leaves():\n",
    "                if str(leaf)==',':\n",
    "                    string += str(leaf)\n",
    "                else:\n",
    "                    string += \" \"+str(leaf)\n",
    "            \n",
    "            test_pos1.append(string.strip())\n",
    "                \n",
    "test_pos1 = list(set(test_pos1))\n",
    "print len(test_pos1)\n",
    "with open('noun_phrase_results/health/entities_train_personalIT_health_test', 'wb') as fp:\n",
    "    pickle.dump(train, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "6183\n"
     ]
    }
   ],
   "source": [
    "print len(set(test_pos1) & set(entities_test))\n",
    "entities_test =  list(set(entities_test) - (set(test_pos1) & set(entities_test)))\n",
    "print len(entities_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['these companies', 'other facility locations', 'third-party sites and applications', 'alert you of new products or services, features, or enhancements ; handle/route your customer service questions or issues', 'Track Signals', 'small bits', 'online interactive communities, your Devices, Digital Content, Apps and software, and display associated content and advertising', \"a child 's first name and the friend 's email address\", 'service bulletins', 'a safe online experience']\n",
      "['the search engine you used to find the Curse Features', 'the categories', 'other click-stream data', 'entry and exit points', 'activity on USA.gov', 'results', 'the items', 'your Service usage activities', 'use of the Sites .', 'CPU']\n"
     ]
    }
   ],
   "source": [
    "print entities_test[:10]\n",
    "print test_pos1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770\n",
      "[([u'your', u'interactions', u'with', u'the', u'websites,', u'apps,', u'and', u'other', u'services', u'you', u'use,', u'the', u'content', u'you', u'view,', u'the', u'search', u'queries', u'you', u'submit,'], 'positive'), ([u'user', u'name,', u'address,', u'other', u'personal', u'information'], 'positive'), ([u'clickstream', u'to,', u'and', u'from', u'our', u'services,', u'including', u'date', u'and', u'time', u'and', u'products', u'you', u'viewed', u'searched'], 'positive'), ([u'other', u'sites', u'subscribers'], 'positive'), ([u'your', u'purchases'], 'positive'), ([u'your', u'device'], 'positive'), ([u'information', u'about', u'user', u'visits'], 'positive'), ([u'pages', u'visited'], 'positive'), ([u'service', u'-lrb-', u'-rrb-', u'you', u'arrived', u'from,', u'and', u'other', u'clickstream', u'data'], 'positive'), ([u'description', u'the', u'page'], 'positive')]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayesian\n",
    "t_set = []\n",
    "for t in train:\n",
    "    t_set.append((unicode(t, 'utf-8'),'positive'))\n",
    "\n",
    "for t in extracted_train:\n",
    "    t_set.append((unicode(t, 'utf-8'),'negative'))\n",
    "    \n",
    "print len(t_set)\n",
    "\n",
    "train_set = []\n",
    "for (words, sentiment) in t_set:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    train_set.append((words_filtered, sentiment))\n",
    "\n",
    "print train_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "# testing data set prep\n",
    "\n",
    "t_set_test = []\n",
    "for t in test_pos1[:200]:\n",
    "    t_set_test.append((unicode(t, 'utf-8'),'positive'))\n",
    "\n",
    "for t in entities_test[:200]:\n",
    "    t_set_test.append((unicode(t, 'utf-8'),'negative'))\n",
    "    \n",
    "print len(t_set_test)\n",
    "\n",
    "test_set = []\n",
    "for (words, sentiment) in t_set_test:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    test_set.append((words_filtered, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl1 = NaiveBayesClassifier(t_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0\n"
     ]
    }
   ],
   "source": [
    "count_pos1 = 0\n",
    "count_neg1 = 0\n",
    "for t in range(len(test_pos1[:20])):\n",
    "    value = cl1.classify(test_pos1[t])\n",
    "    if value is \"negative\": \n",
    "        count_neg1 = count_neg1+1\n",
    "    if value is \"positive\":\n",
    "        count_pos1 = count_pos1+1\n",
    "print count_pos1, count_neg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 8\n"
     ]
    }
   ],
   "source": [
    "count_pos2 = 0\n",
    "count_neg2 = 0\n",
    "for t in range(len(entities_test[:20])):\n",
    "    value = cl1.classify(entities_test[t])\n",
    "    if value is \"negative\":\n",
    "        count_neg2 = count_neg2+1\n",
    "    if value is \"positive\":\n",
    "        count_pos2 = count_pos2+1\n",
    "print count_pos2, count_neg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayesian\n",
      "true positives  - 20\n",
      "false negatives  - 0\n",
      "false positives - 12\n",
      "true negatives - 8\n",
      "accuracy  -  70\n",
      "recall    -  100\n",
      "precision -  62\n"
     ]
    }
   ],
   "source": [
    "print \"Naive Bayesian\"\n",
    "print \"true positives  -\", count_pos1\n",
    "print \"false negatives  -\", count_neg1\n",
    "print \"false positives -\", count_pos2\n",
    "print \"true negatives -\", count_neg2\n",
    "numerator = count_pos1 + count_neg2\n",
    "denominator = count_pos1 + count_neg2 + count_pos2 + count_neg1\n",
    "accuracy = numerator * 100 / denominator\n",
    "print \"accuracy  - \", accuracy\n",
    "print \"recall    - \", 2000/20 # TP/(TP+FN)\n",
    "print \"precision - \", 2000/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "count_pos1 = 0\n",
    "count_neg1 = 0\n",
    "for t in range(len(test_pos1[:50])):\n",
    "    value = classifier1.classify(test_pos1[t])\n",
    "    if value is False:\n",
    "        count_neg1 = count_neg1+1\n",
    "    if value is True:\n",
    "        count_pos1 = count_pos1+1\n",
    "print count_pos1, count_neg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770\n",
      "2770\n"
     ]
    }
   ],
   "source": [
    "naive_bayesian_train_set = []\n",
    "naive_bayesian_train_set.extend(train)\n",
    "naive_bayesian_train_set.extend(extracted_train)\n",
    "print len(naive_bayesian_train_set)\n",
    "\n",
    "naive_bayesian_train_label_set = []\n",
    "for t in train:\n",
    "    naive_bayesian_train_label_set.append('positive')\n",
    "\n",
    "for t in extracted_train:\n",
    "    naive_bayesian_train_label_set.append('negative')\n",
    "    \n",
    "print len(naive_bayesian_train_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...         use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('tfidf_transformer',  TfidfTransformer()),\n",
    "    ('classifier',  MultinomialNB()) ])\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(naive_bayesian_train_set, naive_bayesian_train_label_set)\n",
    "# pipeline.predict(examples) # ['spam', 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_bayesian_train_set_test = []\n",
    "for t in test_pos1[:200]:\n",
    "    naive_bayesian_train_set_test.append(t)\n",
    "\n",
    "for t in entities_test[:200]:\n",
    "    naive_bayesian_train_set_test.append(t)\n",
    "    \n",
    "naive_bayesian_train_label_set_test = []\n",
    "for t in test_pos1[:200]:\n",
    "    naive_bayesian_train_label_set_test.append('positive')\n",
    "\n",
    "for t in entities_test[:200]:\n",
    "    naive_bayesian_train_label_set_test.append('negative')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.76      0.68      0.72       200\n",
      "   positive       0.71      0.79      0.75       200\n",
      "\n",
      "avg / total       0.74      0.73      0.73       400\n",
      "\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "predicted_values = pipeline.predict(naive_bayesian_train_set_test) # ['spam', 'ham']\n",
    "print(classification_report(naive_bayesian_train_label_set_test, predicted_values))\n",
    "\n",
    "print len(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "scores = ['precision', 'recall','accuracy']\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "\n",
    "_ = pipeline.fit(naive_bayesian_train_set, naive_bayesian_train_label_set)\n",
    "svm_train_label_set_test_predict = pipeline.predict(naive_bayesian_train_set_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.70      0.79      0.74       200\n",
      "   positive       0.76      0.66      0.71       200\n",
      "\n",
      "avg / total       0.73      0.72      0.72       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(naive_bayesian_train_label_set_test, svm_train_label_set_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'fit_prior': True, 'class_prior': None}\n",
      "{'kernel': 'rbf', 'verbose': False, 'degree': 3, 'shrinking': True, 'max_iter': -1, 'random_state': None, 'tol': 0.001, 'cache_size': 200, 'coef0': 0.0, 'nu': 0.5, 'gamma': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print MultinomialNB().get_params()\n",
    "print svm.OneClassSVM().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.001       0.00100462  0.00100926  0.00101393  0.00101861  0.00102332\n",
      "  0.00102804  0.00103279  0.00103757  0.00104236  0.00104718  0.00105202\n",
      "  0.00105688  0.00106176  0.00106666  0.00107159  0.00107654  0.00108152\n",
      "  0.00108652  0.00109154  0.00109658  0.00110165  0.00110674  0.00111185\n",
      "  0.00111699  0.00112215  0.00112733  0.00113254  0.00113777  0.00114303\n",
      "  0.00114831  0.00115362  0.00115895  0.0011643   0.00116968  0.00117509\n",
      "  0.00118052  0.00118597  0.00119145  0.00119696  0.00120249  0.00120804\n",
      "  0.00121362  0.00121923  0.00122486  0.00123052  0.00123621  0.00124192\n",
      "  0.00124766  0.00125342  0.00125922  0.00126503  0.00127088  0.00127675\n",
      "  0.00128265  0.00128858  0.00129453  0.00130051  0.00130652  0.00131256\n",
      "  0.00131862  0.00132471  0.00133083  0.00133698  0.00134316  0.00134937\n",
      "  0.0013556   0.00136187  0.00136816  0.00137448  0.00138083  0.00138721\n",
      "  0.00139362  0.00140006  0.00140653  0.00141303  0.00141955  0.00142611\n",
      "  0.0014327   0.00143932  0.00144597  0.00145265  0.00145937  0.00146611\n",
      "  0.00147288  0.00147969  0.00148652  0.00149339  0.00150029  0.00150723\n",
      "  0.00151419  0.00152119  0.00152821  0.00153528  0.00154237  0.0015495\n",
      "  0.00155665  0.00156385  0.00157107  0.00157833  0.00158562  0.00159295\n",
      "  0.00160031  0.0016077   0.00161513  0.0016226   0.00163009  0.00163762\n",
      "  0.00164519  0.00165279  0.00166043  0.0016681   0.00167581  0.00168355\n",
      "  0.00169133  0.00169914  0.00170699  0.00171488  0.00172281  0.00173077\n",
      "  0.00173876  0.0017468   0.00175487  0.00176298  0.00177112  0.0017793\n",
      "  0.00178753  0.00179578  0.00180408  0.00181242  0.00182079  0.0018292\n",
      "  0.00183766  0.00184615  0.00185468  0.00186325  0.00187186  0.0018805\n",
      "  0.00188919  0.00189792  0.00190669  0.0019155   0.00192435  0.00193324\n",
      "  0.00194217  0.00195115  0.00196016  0.00196922  0.00197832  0.00198746\n",
      "  0.00199664  0.00200587  0.00201514  0.00202445  0.0020338   0.0020432\n",
      "  0.00205264  0.00206212  0.00207165  0.00208122  0.00209084  0.0021005\n",
      "  0.0021102   0.00211995  0.00212975  0.00213959  0.00214947  0.00215941\n",
      "  0.00216938  0.00217941  0.00218948  0.00219959  0.00220976  0.00221997\n",
      "  0.00223022  0.00224053  0.00225088  0.00226128  0.00227173  0.00228222\n",
      "  0.00229277  0.00230336  0.00231401  0.0023247   0.00233544  0.00234623\n",
      "  0.00235707  0.00236796  0.0023789   0.00238989  0.00240093  0.00241203\n",
      "  0.00242317  0.00243437  0.00244562  0.00245692  0.00246827  0.00247967\n",
      "  0.00249113  0.00250264  0.0025142   0.00252582  0.00253749  0.00254921\n",
      "  0.00256099  0.00257283  0.00258471  0.00259666  0.00260865  0.00262071\n",
      "  0.00263282  0.00264498  0.0026572   0.00266948  0.00268181  0.0026942\n",
      "  0.00270665  0.00271916  0.00273172  0.00274434  0.00275702  0.00276976\n",
      "  0.00278256  0.00279542  0.00280833  0.00282131  0.00283434  0.00284744\n",
      "  0.0028606   0.00287381  0.00288709  0.00290043  0.00291383  0.00292729\n",
      "  0.00294082  0.00295441  0.00296806  0.00298177  0.00299555  0.00300939\n",
      "  0.00302329  0.00303726  0.0030513   0.0030654   0.00307956  0.00309379\n",
      "  0.00310808  0.00312244  0.00313687  0.00315136  0.00316592  0.00318055\n",
      "  0.00319525  0.00321001  0.00322484  0.00323974  0.00325471  0.00326975\n",
      "  0.00328486  0.00330003  0.00331528  0.0033306   0.00334599  0.00336145\n",
      "  0.00337698  0.00339258  0.00340826  0.00342401  0.00343983  0.00345572\n",
      "  0.00347169  0.00348773  0.00350384  0.00352003  0.0035363   0.00355263\n",
      "  0.00356905  0.00358554  0.00360211  0.00361875  0.00363547  0.00365227\n",
      "  0.00366914  0.0036861   0.00370313  0.00372024  0.00373743  0.00375469\n",
      "  0.00377204  0.00378947  0.00380698  0.00382457  0.00384224  0.00385999\n",
      "  0.00387783  0.00389575  0.00391375  0.00393183  0.00395     0.00396825\n",
      "  0.00398658  0.004005    0.00402351  0.0040421   0.00406077  0.00407953\n",
      "  0.00409838  0.00411732  0.00413634  0.00415546  0.00417466  0.00419394\n",
      "  0.00421332  0.00423279  0.00425235  0.00427199  0.00429173  0.00431156\n",
      "  0.00433148  0.0043515   0.0043716   0.0043918   0.00441209  0.00443248\n",
      "  0.00445296  0.00447353  0.0044942   0.00451497  0.00453583  0.00455679\n",
      "  0.00457784  0.00459899  0.00462024  0.00464159  0.00466303  0.00468458\n",
      "  0.00470622  0.00472797  0.00474981  0.00477176  0.00479381  0.00481596\n",
      "  0.00483821  0.00486056  0.00488302  0.00490558  0.00492825  0.00495102\n",
      "  0.0049739   0.00499688  0.00501997  0.00504316  0.00506646  0.00508987\n",
      "  0.00511339  0.00513701  0.00516075  0.00518459  0.00520855  0.00523261\n",
      "  0.00525679  0.00528108  0.00530548  0.00532999  0.00535462  0.00537936\n",
      "  0.00540422  0.00542919  0.00545427  0.00547947  0.00550479  0.00553022\n",
      "  0.00555578  0.00558145  0.00560723  0.00563314  0.00565917  0.00568532\n",
      "  0.00571159  0.00573798  0.00576449  0.00579112  0.00581788  0.00584476\n",
      "  0.00587177  0.0058989   0.00592615  0.00595353  0.00598104  0.00600868\n",
      "  0.00603644  0.00606433  0.00609235  0.0061205   0.00614878  0.00617719\n",
      "  0.00620573  0.0062344   0.00626321  0.00629215  0.00632122  0.00635043\n",
      "  0.00637977  0.00640924  0.00643886  0.00646861  0.0064985   0.00652852\n",
      "  0.00655869  0.00658899  0.00661943  0.00665002  0.00668074  0.00671161\n",
      "  0.00674262  0.00677378  0.00680507  0.00683652  0.0068681   0.00689984\n",
      "  0.00693172  0.00696374  0.00699592  0.00702824  0.00706072  0.00709334\n",
      "  0.00712612  0.00715904  0.00719212  0.00722535  0.00725873  0.00729227\n",
      "  0.00732597  0.00735981  0.00739382  0.00742798  0.0074623   0.00749678\n",
      "  0.00753142  0.00756622  0.00760118  0.0076363   0.00767158  0.00770703\n",
      "  0.00774264  0.00777841  0.00781435  0.00785046  0.00788673  0.00792317\n",
      "  0.00795978  0.00799655  0.0080335   0.00807062  0.00810791  0.00814537\n",
      "  0.00818301  0.00822082  0.0082588   0.00829696  0.00833529  0.00837381\n",
      "  0.0084125   0.00845137  0.00849042  0.00852964  0.00856906  0.00860865\n",
      "  0.00864842  0.00868838  0.00872853  0.00876886  0.00880937  0.00885007\n",
      "  0.00889097  0.00893205  0.00897332  0.00901478  0.00905643  0.00909827\n",
      "  0.00914031  0.00918254  0.00922497  0.00926759  0.00931041  0.00935343\n",
      "  0.00939665  0.00944006  0.00948368  0.0095275   0.00957152  0.00961575\n",
      "  0.00966017  0.00970481  0.00974965  0.0097947   0.00983995  0.00988542\n",
      "  0.00993109  0.00997698  0.01002308  0.01006939  0.01011591  0.01016265\n",
      "  0.01020961  0.01025678  0.01030417  0.01035178  0.01039961  0.01044766\n",
      "  0.01049593  0.01054443  0.01059315  0.01064209  0.01069126  0.01074066\n",
      "  0.01079029  0.01084014  0.01089023  0.01094055  0.0109911   0.01104188\n",
      "  0.0110929   0.01114415  0.01119564  0.01124737  0.01129934  0.01135155\n",
      "  0.011404    0.01145669  0.01150962  0.0115628   0.01161623  0.0116699\n",
      "  0.01172382  0.01177799  0.01183241  0.01188708  0.011942    0.01199718\n",
      "  0.01205261  0.0121083   0.01216424  0.01222045  0.01227691  0.01233363\n",
      "  0.01239062  0.01244787  0.01250539  0.01256317  0.01262121  0.01267953\n",
      "  0.01273811  0.01279697  0.0128561   0.0129155   0.01297517  0.01303512\n",
      "  0.01309535  0.01315586  0.01321664  0.01327771  0.01333906  0.01340069\n",
      "  0.01346261  0.01352481  0.0135873   0.01365008  0.01371315  0.01377651\n",
      "  0.01384016  0.01390411  0.01396835  0.01403289  0.01409773  0.01416287\n",
      "  0.0142283   0.01429405  0.01436009  0.01442644  0.0144931   0.01456006\n",
      "  0.01462733  0.01469492  0.01476281  0.01483103  0.01489955  0.01496839\n",
      "  0.01503755  0.01510703  0.01517683  0.01524696  0.0153174   0.01538818\n",
      "  0.01545928  0.01553071  0.01560246  0.01567455  0.01574698  0.01581973\n",
      "  0.01589283  0.01596626  0.01604003  0.01611414  0.0161886   0.0162634\n",
      "  0.01633854  0.01641403  0.01648987  0.01656606  0.0166426   0.0167195\n",
      "  0.01679675  0.01687436  0.01695232  0.01703065  0.01710934  0.01718839\n",
      "  0.01726781  0.01734759  0.01742775  0.01750827  0.01758917  0.01767044\n",
      "  0.01775208  0.0178341   0.0179165   0.01799929  0.01808245  0.018166\n",
      "  0.01824993  0.01833425  0.01841897  0.01850407  0.01858957  0.01867546\n",
      "  0.01876175  0.01884843  0.01893552  0.01902301  0.01911091  0.01919921\n",
      "  0.01928792  0.01937703  0.01946656  0.01955651  0.01964687  0.01973764\n",
      "  0.01982884  0.01992046  0.0200125   0.02010496  0.02019786  0.02029118\n",
      "  0.02038493  0.02047912  0.02057374  0.0206688   0.0207643   0.02086024\n",
      "  0.02095662  0.02105345  0.02115073  0.02124845  0.02134663  0.02144526\n",
      "  0.02154435  0.02164389  0.02174389  0.02184436  0.02194529  0.02204669\n",
      "  0.02214855  0.02225089  0.0223537   0.02245698  0.02256074  0.02266498\n",
      "  0.0227697   0.02287491  0.0229806   0.02308678  0.02319345  0.02330061\n",
      "  0.02340827  0.02351643  0.02362508  0.02373424  0.0238439   0.02395407\n",
      "  0.02406475  0.02417594  0.02428764  0.02439986  0.0245126   0.02462586\n",
      "  0.02473964  0.02485395  0.02496878  0.02508415  0.02520005  0.02531648\n",
      "  0.02543346  0.02555097  0.02566903  0.02578763  0.02590678  0.02602648\n",
      "  0.02614673  0.02626754  0.02638891  0.02651084  0.02663333  0.02675638\n",
      "  0.02688001  0.02700421  0.02712898  0.02725433  0.02738025  0.02750676\n",
      "  0.02763385  0.02776153  0.0278898   0.02801867  0.02814812  0.02827818\n",
      "  0.02840884  0.0285401   0.02867196  0.02880444  0.02893753  0.02907123\n",
      "  0.02920556  0.0293405   0.02947606  0.02961225  0.02974908  0.02988653\n",
      "  0.03002462  0.03016334  0.03030271  0.03044272  0.03058338  0.03072469\n",
      "  0.03086665  0.03100927  0.03115254  0.03129648  0.03144108  0.03158635\n",
      "  0.0317323   0.03187891  0.03202621  0.03217418  0.03232284  0.03247218\n",
      "  0.03262222  0.03277295  0.03292437  0.0330765   0.03322933  0.03338286\n",
      "  0.0335371   0.03369206  0.03384773  0.03400412  0.03416123  0.03431907\n",
      "  0.03447764  0.03463694  0.03479698  0.03495776  0.03511928  0.03528154\n",
      "  0.03544456  0.03560833  0.03577285  0.03593814  0.03610419  0.036271\n",
      "  0.03643859  0.03660695  0.03677609  0.03694601  0.03711672  0.03728821\n",
      "  0.0374605   0.03763358  0.03780747  0.03798215  0.03815765  0.03833395\n",
      "  0.03851107  0.03868901  0.03886777  0.03904735  0.03922777  0.03940902\n",
      "  0.0395911   0.03977403  0.0399578   0.04014242  0.0403279   0.04051423\n",
      "  0.04070142  0.04088948  0.04107841  0.04126821  0.04145888  0.04165044\n",
      "  0.04184289  0.04203622  0.04223044  0.04242556  0.04262159  0.04281852\n",
      "  0.04301636  0.04321511  0.04341478  0.04361538  0.0438169   0.04401935\n",
      "  0.04422274  0.04442707  0.04463234  0.04483856  0.04504573  0.04525386\n",
      "  0.04546295  0.04567301  0.04588404  0.04609604  0.04630903  0.046523\n",
      "  0.04673795  0.0469539   0.04717085  0.0473888   0.04760775  0.04782772\n",
      "  0.0480487   0.04827071  0.04849374  0.0487178   0.0489429   0.04916904\n",
      "  0.04939622  0.04962445  0.04985373  0.05008408  0.05031549  0.05054797\n",
      "  0.05078152  0.05101615  0.05125187  0.05148867  0.05172657  0.05196557\n",
      "  0.05220568  0.05244689  0.05268921  0.05293266  0.05317723  0.05342293\n",
      "  0.05366977  0.05391775  0.05416687  0.05441714  0.05466857  0.05492116\n",
      "  0.05517492  0.05542986  0.05568596  0.05594326  0.05620174  0.05646141\n",
      "  0.05672229  0.05698437  0.05724766  0.05751217  0.0577779   0.05804486\n",
      "  0.05831305  0.05858248  0.05885316  0.05912508  0.05939827  0.05967271\n",
      "  0.05994843  0.06022541  0.06050368  0.06078323  0.06106408  0.06134622\n",
      "  0.06162966  0.06191442  0.06220049  0.06248788  0.0627766   0.06306666\n",
      "  0.06335805  0.06365079  0.06394488  0.06424034  0.06453715  0.06483534\n",
      "  0.06513491  0.06543586  0.0657382   0.06604194  0.06634708  0.06665363\n",
      "  0.0669616   0.06727099  0.06758181  0.06789407  0.06820777  0.06852292\n",
      "  0.06883952  0.06915759  0.06947713  0.06979814  0.07012064  0.07044462\n",
      "  0.07077011  0.07109709  0.07142559  0.07175561  0.07208715  0.07242022\n",
      "  0.07275484  0.07309099  0.0734287   0.07376798  0.07410882  0.07445123\n",
      "  0.07479523  0.07514081  0.07548799  0.07583678  0.07618718  0.07653919\n",
      "  0.07689284  0.07724811  0.07760503  0.0779636   0.07832383  0.07868572\n",
      "  0.07904928  0.07941452  0.07978145  0.08015007  0.0805204   0.08089243\n",
      "  0.08126619  0.08164168  0.08201889  0.08239786  0.08277857  0.08316104\n",
      "  0.08354528  0.08393129  0.08431909  0.08470868  0.08510007  0.08549327\n",
      "  0.08588829  0.08628513  0.0866838   0.08708431  0.08748668  0.08789091\n",
      "  0.088297    0.08870497  0.08911482  0.08952657  0.08994022  0.09035578\n",
      "  0.09077327  0.09119268  0.09161402  0.09203732  0.09246257  0.09288979\n",
      "  0.09331898  0.09375015  0.09418332  0.09461848  0.09505566  0.09549486\n",
      "  0.09593608  0.09637935  0.09682466  0.09727203  0.09772147  0.09817298\n",
      "  0.09862658  0.09908228  0.09954008  0.1       ]\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-3, -1, 1000)\n",
    "alpha_range = np.logspace(-3, -1, 1000)\n",
    "\n",
    "param_grid = dict(clf__alpha=gamma_range)\n",
    "print alpha_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__alpha': array([ 0.001  ,  0.001  , ...,  0.09954,  0.1    ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "scores = ['precision', 'recall','accuracy']\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, scoring=\"accuracy\", cv=10)\n",
    "grid.fit(naive_bayesian_train_set, naive_bayesian_train_label_set)\n",
    "\n",
    "\n",
    "# print \"Performing grid search...\"\n",
    "# print \"pipeline:\", [name for name, _ in pipeline.steps]\n",
    "# print \"parameters:\"\n",
    "# # pprint parameters\n",
    "# grid_search.fit(train, data_targets)\n",
    "# print \"\"\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Best score: 0.887\n",
      "predicted accuracy  0.825\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.80      0.87      0.83       100\n",
      "   positive       0.86      0.78      0.82       100\n",
      "\n",
      "avg / total       0.83      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# no. of folds  = 10\n",
    "print grid.best_estimator_.get_params()['clf'].get_params()['alpha'] \n",
    "print(\"Best score: %0.3f\" % grid.best_score_)\n",
    "print \"predicted accuracy \", grid.score(naive_bayesian_train_set_test, naive_bayesian_train_label_set_test) \n",
    "\n",
    "naive_bayesian_train_label_set_test_predict = grid.predict(naive_bayesian_train_set_test)\n",
    "print(classification_report(naive_bayesian_train_label_set_test, naive_bayesian_train_label_set_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel', 'C', 'verbose', 'probability', 'degree', 'shrinking', 'max_iter', 'decision_function_shape', 'random_state', 'tol', 'cache_size', 'coef0', 'gamma', 'class_weight']\n"
     ]
    }
   ],
   "source": [
    "C = range(1, 10)\n",
    "param_grid_svm = [\n",
    "  {'clf__C': C, 'clf__kernel': ['linear']},\n",
    "  {'clf__C': C, 'clf__gamma': np.logspace(-3, -1, 100), 'clf__kernel': ['rbf']},\n",
    "]\n",
    "print svm.SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'clf__C': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'clf__kernel': ['linear']}, {'clf__gamma': array([ 0.001  ,  0.00105, ...,  0.09545,  0.1    ]), 'clf__C': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'clf__kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "scores = ['precision', 'recall','accuracy']\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', svm.SVC())])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid_svm, scoring=\"accuracy\", cv=10)\n",
    "grid.fit(naive_bayesian_train_set, naive_bayesian_train_label_set)\n",
    "\n",
    "\n",
    "# print \"Performing grid search...\"\n",
    "# print \"pipeline:\", [name for name, _ in pipeline.steps]\n",
    "# print \"parameters:\"\n",
    "# # pprint parameters\n",
    "# grid_search.fit(train, data_targets)\n",
    "# print \"\"\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 5\n",
      "Best Kernel: rbf\n",
      "Best Gamma: 0.0911162756115\n",
      "Best score: 0.876\n",
      "predicted accuracy  0.865\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.85      0.89      0.87       100\n",
      "   positive       0.88      0.84      0.86       100\n",
      "\n",
      "avg / total       0.87      0.86      0.86       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print 'Best C:',grid.best_estimator_.get_params()['clf'].get_params()['C']\n",
    "print 'Best Kernel:',grid.best_estimator_.get_params()['clf__kernel']\n",
    "print 'Best Gamma:',grid.best_estimator_.get_params()['clf'].get_params()['gamma']\n",
    "print \"Best score: %0.3f\" % grid.best_score_\n",
    "print \"predicted accuracy \", grid.score(naive_bayesian_train_set_test, naive_bayesian_train_label_set_test) \n",
    "\n",
    "naive_bayesian_train_label_set_test_predict = grid.predict(naive_bayesian_train_set_test)\n",
    "print(classification_report(naive_bayesian_train_label_set_test, naive_bayesian_train_label_set_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'clf__gamma': 1.0000000000000001e-09, 'clf__nu': 0.1} with a score of 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', svm.OneClassSVM())])\n",
    "\n",
    "nu_range = [0.1, 0.3, 0.5, 0.7]\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(clf__nu = nu_range, clf__gamma=gamma_range)\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "grid_oneclass = GridSearchCV(pipeline, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid_oneclass.fit(naive_bayesian_train_set, naive_bayesian_train_label_set)\n",
    "print(\"The best parameters are %s with a score of %0.3f\"\n",
    "      % (grid_oneclass.best_params_, grid_oneclass.best_score_))\n",
    "\n",
    "# print \"Performing grid search...\"\n",
    "# print \"pipeline:\", [name for name, _ in pipeline.steps]\n",
    "# print \"parameters:\"\n",
    "# # pprint parameters\n",
    "# grid_search.fit(train, data_targets)\n",
    "# print \"\"\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted accuracy  0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-3a7bb2bec298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnaive_bayesian_train_label_set_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_oneclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_bayesian_train_set_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_bayesian_train_label_set_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaive_bayesian_train_label_set_test_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/aryan/anaconda/envs/aryan_env/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aryan/anaconda/envs/aryan_env/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# print 'Best C:',grid_oneclass.best_estimator_.get_params()['clf'].get_params()['C']\n",
    "# print 'Best Kernel:',grid_oneclass.best_estimator_.get_params()['clf__kernel']\n",
    "# print 'Best Gamma:',grid_oneclass.best_estimator_.get_params()['clf'].get_params()['gamma']\n",
    "# print \"Best score: %0.3f\" % grid_oneclass.best_score_\n",
    "print \"predicted accuracy \", grid_oneclass.score(naive_bayesian_train_set_test, naive_bayesian_train_label_set_test) \n",
    "\n",
    "naive_bayesian_train_label_set_test_predict = grid_oneclass.predict(naive_bayesian_train_set_test)\n",
    "print(classification_report(naive_bayesian_train_label_set_test, naive_bayesian_train_label_set_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firstParty_entities = []\n",
    "firstParty_labels = []\n",
    "for i in firstParty_train:\n",
    "    firstParty_labels.append('positive')\n",
    "    firstParty_entities.append(i)\n",
    "    \n",
    "for i in range(len(firstParty_train)):\n",
    "    firstParty_labels.append('negative')\n",
    "    firstParty_entities.append(entities_train[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__alpha': array([ 0.001  ,  0.00167,  0.00278,  0.00464,  0.00774,  0.01292,\n",
       "        0.02154,  0.03594,  0.05995,  0.1    ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Combination Analysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "scores = ['precision', 'recall','accuracy']\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "C_range = np.logspace(-2, 10, 5)\n",
    "gamma_range = np.logspace(-3, -1, 10)\n",
    "alpha_range = np.logspace(-3, -1, 10)\n",
    "\n",
    "param_grid = dict(clf__alpha=gamma_range)\n",
    "\n",
    "grid_firstParty = GridSearchCV(pipeline, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid_firstParty.fit(firstParty_entities, firstParty_labels)\n",
    "\n",
    "\n",
    "# print \"Performing grid search...\"\n",
    "# print \"pipeline:\", [name for name, _ in pipeline.steps]\n",
    "# print \"parameters:\"\n",
    "# # pprint parameters\n",
    "# grid_search.fit(train, data_targets)\n",
    "# print \"\"\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted accuracy  0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.89      0.83       100\n",
      "   positive       0.87      0.75      0.81       100\n",
      "\n",
      "avg / total       0.83      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# print 'Best C:',grid_oneclass.best_estimator_.get_params()['clf'].get_params()['C']\n",
    "# print 'Best Kernel:',grid_oneclass.best_estimator_.get_params()['clf__kernel']\n",
    "# print 'Best Gamma:',grid_oneclass.best_estimator_.get_params()['clf'].get_params()['gamma']\n",
    "# print \"Best score: %0.3f\" % grid_oneclass.best_score_\n",
    "print \"predicted accuracy \", grid_firstParty.score(naive_bayesian_train_set_test, naive_bayesian_train_label_set_test) \n",
    "\n",
    "naive_bayesian_train_label_set_test_predict = grid_firstParty.predict(naive_bayesian_train_set_test)\n",
    "print(classification_report(naive_bayesian_train_label_set_test, naive_bayesian_train_label_set_test_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
